{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4932759,
          "sourceType": "datasetVersion",
          "datasetId": 2860500
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Forest fire Detection Using Satellite Imagery",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udayfulkatwar/Green-AI-Workshop/blob/main/Forest_fire_Detection_Using_Satellite_Imagery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "abdelghaniaaba_wildfire_prediction_dataset_path = kagglehub.dataset_download('abdelghaniaaba/wildfire-prediction-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GAZMv9T4pYKb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "from PIL import Image, ImageTk\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:40:02.000488Z",
          "iopub.execute_input": "2025-01-10T08:40:02.000738Z",
          "iopub.status.idle": "2025-01-10T08:40:13.598655Z",
          "shell.execute_reply.started": "2025-01-10T08:40:02.000712Z",
          "shell.execute_reply": "2025-01-10T08:40:13.597064Z"
        },
        "id": "95i8ipDepYKc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = r\"/kaggle/input/wildfire-prediction-dataset/train\"\n",
        "valid_dir = r\"/kaggle/input/wildfire-prediction-dataset/valid\"\n",
        "test_dir = r\"/kaggle/input/wildfire-prediction-dataset/test\"\n",
        "\n",
        "#set up ImageDateGenerator for loading images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_dategen = ImageDataGenerator(rescale=1./255)\n",
        "test_dategen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Load image for Directories\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "valid_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "test_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:05.787924Z",
          "iopub.execute_input": "2025-01-10T08:48:05.788391Z",
          "iopub.status.idle": "2025-01-10T08:48:51.306557Z",
          "shell.execute_reply.started": "2025-01-10T08:48:05.788359Z",
          "shell.execute_reply": "2025-01-10T08:48:51.30518Z"
        },
        "id": "2BmMlpq6pYKc",
        "outputId": "6d83cb7c-78a5-4d18-b624-a2741605b3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 30250 images belonging to 2 classes.\nFound 30250 images belonging to 2 classes.\nFound 30250 images belonging to 2 classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:07:12.308047Z",
          "iopub.execute_input": "2025-01-10T09:07:12.308433Z",
          "iopub.status.idle": "2025-01-10T09:07:12.373081Z",
          "shell.execute_reply.started": "2025-01-10T09:07:12.308404Z",
          "shell.execute_reply": "2025-01-10T09:07:12.371769Z"
        },
        "id": "9aBJup-RpYKd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "trusted": true,
        "id": "48kCH6ETpYKd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=1, verbose=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:45:22.882109Z",
          "iopub.execute_input": "2025-01-10T09:45:22.88268Z",
          "iopub.status.idle": "2025-01-10T09:49:15.514626Z",
          "shell.execute_reply.started": "2025-01-10T09:45:22.882637Z",
          "shell.execute_reply": "2025-01-10T09:49:15.51312Z"
        },
        "id": "h3UWAb42pYKe",
        "outputId": "081866bd-4310-441f-8abc-b1cf7b27abf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 245ms/step - accuracy: 0.9579 - loss: 0.1166 - val_accuracy: 0.9685 - val_loss: 0.0872\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"fdd_model.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:53:22.596804Z",
          "iopub.execute_input": "2025-01-10T09:53:22.59715Z",
          "iopub.status.idle": "2025-01-10T09:53:22.67392Z",
          "shell.execute_reply.started": "2025-01-10T09:53:22.597124Z",
          "shell.execute_reply": "2025-01-10T09:53:22.672467Z"
        },
        "id": "sAd3EG6rpYKe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and predict an image\n",
        "def predict_image():\n",
        "    # Open file dialog to select an image\n",
        "    file_path = filedialog.askopenfilename()\n",
        "    if file_path:\n",
        "        # Display the image in the GUI\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((200, 200))\n",
        "        img = ImageTk.PhotoImage(img)    #convert image for tk\n",
        "        image_label.configure(image=img) #update the image in GUI\n",
        "        image_label.image = img\n",
        "\n",
        "        # Preprocess the image for the model\n",
        "        img_for_model = Image.open(file_path).resize((64, 64))\n",
        "        img_array = np.array(img_for_model) / 255.0  # Rescale like during training\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(img_array)[0][0] #extracts the scalar prediction value\n",
        "        result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
        "        result_label.config(text=\"Prediction: \" + result)\n",
        "\n",
        "# Setting up the GUI window\n",
        "root = tk.Tk()\n",
        "root.title(\"Forest Fire Detection\")\n",
        "root.geometry(\"400x400\")\n",
        "\n",
        "# Add widgets\n",
        "btn = tk.Button(root, text=\"Upload Image\", command=predict_image) #button triggers the predict_image() function when clicked\n",
        "btn.pack(pady=20)\n",
        "\n",
        "#Placeholder for displaying the selected image\n",
        "image_label = tk.Label(root)\n",
        "image_label.pack()\n",
        "\n",
        "#Label to display the prediction result\n",
        "result_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 16))\n",
        "result_label.pack(pady=20)\n",
        "\n",
        "#Starts the Tkinter event loop, keeping the GUI active until manually closed\n",
        "root.mainloop()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SvHKex5bpYKe"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}